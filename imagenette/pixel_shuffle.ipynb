{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "028b236b-3f58-42ff-9798-afcb4fb99349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7c45f8b-ce7c-4697-ae19-587a253b6bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_shuffle(inputs, upscale_factor):\n",
    "    \"\"\"Rearranges elements in a tensor of shape [*, C*r^N, D1, D2, ... DN] to a\n",
    "    tensor of shape [*, C, D1*r, D2*r, ... DN*r].\n",
    "    \n",
    "    See the paper:\n",
    "    `Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network`_\n",
    "    by Shi et. al (2016) for more details.\n",
    "    \n",
    "    Args:\n",
    "        inputs (Variable): Inputs\n",
    "        upscale_factor (int): factor to increase spatial resolution by\n",
    "    Examples:\n",
    "        >>> inputs = torch.randn(1, 64, 10, 10, 10))\n",
    "        >>> output = pixel_shuffle(inputs, 4)\n",
    "        >>> print(output.size())\n",
    "        torch.Size([1, 1, 40, 40, 40])\n",
    "    \"\"\"\n",
    "    batch_size, channels, *dims = inputs.size()\n",
    "    N = len(dims)\n",
    "    channels //= (upscale_factor ** N)\n",
    "    inputs_view = inputs.contiguous().view(batch_size, channels, *(upscale_factor for i in range(N)), *dims) # (bs, ch, r, ... r, d1, .... dN)\n",
    "\n",
    "    permute = [ _ for i in range(2 * N)]\n",
    "    permute[::2] = range(N + 2, 2 * N + 2)\n",
    "    permute[1::2] = range(2, N + 2)\n",
    "    \n",
    "    # (bs, ch, r, ... r, d1, .... dN) -> (bs, ch, d1, r, d2, r, ... dN, r), idx: (0, 1, N + 2, 2, ... N + 1 + i, 2 + i, ... 2N + 1, N + 1)\n",
    "    shuffle_out = inputs_view.permute(0, 1, *permute).contiguous()  \n",
    "    out_dims = [dim * upscale_factor for dim in dims]\n",
    "    return shuffle_out.view(batch_size, channels, *out_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e52dd57d-f9ad-4526-9294-774685cb0ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_unshuffle(inputs, downscale_factor):\n",
    "    \"\"\"Reverses `pixel_shuffle` operation by rearranging elements\n",
    "    in a tensor of shape [*, C, D1*r, D2*r, ... DN*r] to a tensor of shape\n",
    "    [*, C*r^N, D1, DN], where r is a downscale factor.\n",
    "\n",
    "    See the paper:\n",
    "    `Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network`_\n",
    "    by Shi et. al (2016) for more details.\n",
    "    \n",
    "    Args:\n",
    "        inputs (Variable): Inputs\n",
    "        downscale_factor (int): factor to decrease spatial resolution by\n",
    "    \"\"\"\n",
    "    batch_size, channels, *dims = inputs.size()\n",
    "    N = len(dims)\n",
    "\n",
    "    out_channels = channels * downscale_factor ** N\n",
    "    out_dims = [dim // downscale_factor for dim in dims]\n",
    "\n",
    "    reshape = [ _ for i in range(2 * N)]\n",
    "    reshape[::2] = out_dims\n",
    "    reshape[1::2] = [downscale_factor for i in range(N)]\n",
    "\n",
    "    after_view = inputs.view(batch_size, channels, *reshape)    # undo the last view\n",
    "\n",
    "    # (bs, ch, d1, r, d2, r, ... dN, r) -> (bs, ch, r, ... r, d1, .... dN) , idx: (0, 1, 3, 5, ... 2N + 1, 2, 4, ... 2N)\n",
    "    permute = [ _ for i in range(2 * N)]\n",
    "    permute[:2 * N] = range(3, 2 * N + 2, 2)\n",
    "    permute[2 * N:] = range(2, 2 * N + 1, 2)\n",
    "\n",
    "    after_shuffle = after_view.permute(0, 1, *permute).contiguous()    # undo permutation\n",
    "    return after_shuffle.view(batch_size, out_channels, *out_dims).contiguous()    # undo the first view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8779e36f-b11b-4d28-ad14-0b8250b8a930",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn(1, 64, 2, 3, 4)\n",
    "factor = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ca9bfa0-1af7-45f6-8abd-2c5fc3ec1e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs shape:  torch.Size([1, 64, 2, 3, 4])\n",
      "shuffled shape:  torch.Size([1, 1, 8, 12, 16])\n",
      "unshuffled shape:  torch.Size([1, 64, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "print('inputs shape: ', inputs.size())\n",
    "shuffled = pixel_shuffle(inputs, factor)\n",
    "print('shuffled shape: ', shuffled.size())\n",
    "unshuffled = pixel_unshuffle(shuffled, factor)\n",
    "print('unshuffled shape: ', unshuffled.size())\n",
    "\n",
    "assert np.all(unshuffled.numpy() == inputs.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
