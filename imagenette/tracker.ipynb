{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ddb0ed-0e09-4290-a2e4-233fd7aa4d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# add no_grad\n",
    "# compare resnets\n",
    "# look into memory_stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72084d1d-e3fd-4611-ae04-de95a21169b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%env CUDA_VISIBLE_DEVICES = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "251aa0d4-8dfc-4594-a378-0005bc2086f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gc\n",
    "import time\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim \n",
    "\n",
    "from models import Resnet, ResnetD, ResNext\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8733d67c-b570-4c63-abb6-cbb98ad134f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f25d5f57-7c22-44bc-8454-8e650196ff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracker:\n",
    "    def __init__(self, device, repeats=100, warmup=0, verbose=True):\n",
    "        self.device = device \n",
    "        self.repeats = repeats\n",
    "        self.warmup = warmup  \n",
    "        self.verbose = verbose\n",
    "        self.start = torch.cuda.Event(enable_timing=True)\n",
    "        self.end = torch.cuda.Event(enable_timing=True)\n",
    "        \n",
    "        \n",
    "    def get_current_memory(self):\n",
    "        return torch.cuda.memory_stats(device=self.device)['active_bytes.all.current'] * 1e-6\n",
    "    \n",
    "    \n",
    "    def track(self, module, inputs): # add no_grad ?\n",
    "        \n",
    "        current_memory = self.get_current_memory()\n",
    "        \n",
    "        self.start.record()\n",
    "        module.to(self.device)\n",
    "        self.end.record()\n",
    "        \n",
    "        torch.cuda.synchronize()\n",
    "        loading_time = self.start.elapsed_time(self.end)\n",
    "        \n",
    "        new_current_memory = self.get_current_memory()\n",
    "        module_memory_consumption = new_current_memory - current_memory\n",
    "        \n",
    "        timings = np.zeros(self.repeats)\n",
    "        memory_on_runs = np.zeros(self.repeats)\n",
    "        \n",
    "        for i in range(self.warmup):\n",
    "            outputs = module(inputs)\n",
    "        \n",
    "        for i in range(self.warmup, self.repeats):\n",
    "\n",
    "            self.start.record()\n",
    "            outputs = module(inputs)\n",
    "            self.end.record()\n",
    "\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "            timings[i] = self.start.elapsed_time(self.end)\n",
    "            memory_on_runs[i] = self.get_current_memory() - current_memory\n",
    "            \n",
    "            del outputs\n",
    "            \n",
    "        if self.verbose:\n",
    "            print(f' {module}: run takes {timings.mean():.2f} +- {timings.std():.2f}s, loaded on cuda in {loading_time}s, \\n'\n",
    "                  f'    module size {module_memory_consumption:.2f} MB, outputs size {memory_on_runs.mean():.2f} MB') \n",
    "            \n",
    "        del module\n",
    "        del inputs\n",
    "            \n",
    "        return timings.mean(), memory_on_runs.mean()\n",
    "    \n",
    "    \n",
    "    def track_module_collection(self, module_collection, inputs):\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        current_memory = self.get_current_memory()\n",
    "        \n",
    "        self.start.record()\n",
    "        inputs = inputs.to(self.device)\n",
    "        self.end.record()\n",
    "        \n",
    "        torch.cuda.synchronize()\n",
    "        \n",
    "        inputs_memory = self.get_current_memory() - current_memory\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f'inputs: shape: {inputs.shape},'\n",
    "                  f'loaded on cuda in: {self.start.elapsed_time(self.end):.2f}s, '\n",
    "                  f'memory consumption: {inputs_memory:.2f} MB')\n",
    "        \n",
    "        \n",
    "        module_collection_stats = np.zeros((len(module_collection), 2))\n",
    "        \n",
    "        for i, module in enumerate(module_collection):\n",
    "            module_collection_stats[i] = self.track(module=module, inputs=inputs)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f'\\nfastest module is {module_collection[module_collection_stats[:, 0].argmin()]} '\n",
    "                    f'with {module_collection_stats[:, 0].min():.2f}s')\n",
    "            print(f'slowest module is {module_collection[module_collection_stats[:, 0].argmax()]} '\n",
    "                    f'with {module_collection_stats[:, 0].max():.2f}s\\n')\n",
    "            print(f'tiniest module is {module_collection[module_collection_stats[:, 1].argmin()]} '\n",
    "                    f'with {module_collection_stats[:, 1].min():.2f}MB')\n",
    "            print(f'largest module is {module_collection[module_collection_stats[:, 1].argmax()]} '\n",
    "                    f'with {module_collection_stats[:, 1].max():.2f}MB')\n",
    "            \n",
    "        return module_collection_stats\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e0b3beee-315a-46e2-9fbc-4d8151347704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: shape: torch.Size([1, 64, 224, 224]),loaded on cuda in: 3.81s, memory consumption: 12.85 MB\n",
      " Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1)): run takes 0.90 +- 0.03s, loaded on cuda in 0.5769919753074646s, \n",
      "    module size 0.13 MB, outputs size 102.89 MB\n",
      " Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1)): run takes 2.40 +- 0.17s, loaded on cuda in 0.48287999629974365s, \n",
      "    module size 1.18 MB, outputs size 102.12 MB\n",
      " Conv2d(64, 512, kernel_size=(5, 5), stride=(1, 1)): run takes 6.08 +- 0.07s, loaded on cuda in 0.8868160247802734s, \n",
      "    module size 3.28 MB, outputs size 102.40 MB\n",
      " Conv2d(64, 512, kernel_size=(7, 7), stride=(1, 1)): run takes 11.34 +- 0.13s, loaded on cuda in 1.5015360116958618s, \n",
      "    module size 6.42 MB, outputs size 103.75 MB\n",
      " Conv2d(64, 512, kernel_size=(7, 7), stride=(1, 1), groups=2): run takes 5.90 +- 0.05s, loaded on cuda in 0.8563519716262817s, \n",
      "    module size 3.21 MB, outputs size 100.54 MB\n",
      " Conv2d(64, 512, kernel_size=(7, 7), stride=(1, 1), groups=4): run takes 3.15 +- 0.03s, loaded on cuda in 0.495743989944458s, \n",
      "    module size 1.61 MB, outputs size 98.94 MB\n",
      " Conv2d(64, 512, kernel_size=(7, 7), stride=(1, 1), groups=8): run takes 1.80 +- 0.02s, loaded on cuda in 0.422432005405426s, \n",
      "    module size 0.80 MB, outputs size 98.13 MB\n",
      " Conv2d(64, 512, kernel_size=(7, 7), stride=(1, 1), groups=16): run takes 1.24 +- 0.01s, loaded on cuda in 0.32528001070022583s, \n",
      "    module size 0.40 MB, outputs size 97.73 MB\n",
      " Conv2d(64, 512, kernel_size=(7, 7), stride=(1, 1), groups=64): run takes 2.17 +- 0.01s, loaded on cuda in 0.450655996799469s, \n",
      "    module size 0.10 MB, outputs size 97.43 MB\n",
      "\n",
      "fastest module is Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1)) with 0.90s\n",
      "slowest module is Conv2d(64, 512, kernel_size=(7, 7), stride=(1, 1)) with 11.34s\n",
      "\n",
      "tiniest module is Conv2d(64, 512, kernel_size=(7, 7), stride=(1, 1), groups=64) with 97.43MB\n",
      "biggest module is Conv2d(64, 512, kernel_size=(7, 7), stride=(1, 1)) with 103.75MB\n"
     ]
    }
   ],
   "source": [
    "tracker = Tracker(device)\n",
    "inputs = torch.randn((1, 64, 224, 224))\n",
    "\n",
    "module_collection = [nn.Conv2d(kernel_size=1, in_channels=64, out_channels=512), \n",
    "                      nn.Conv2d(kernel_size=3, in_channels=64, out_channels=512), \n",
    "                      nn.Conv2d(kernel_size=5, in_channels=64, out_channels=512),\n",
    "                      nn.Conv2d(kernel_size=7, in_channels=64, out_channels=512),\n",
    "                      nn.Conv2d(kernel_size=7, in_channels=64, out_channels=512, groups=2),\n",
    "                      nn.Conv2d(kernel_size=7, in_channels=64, out_channels=512, groups=4),\n",
    "                      nn.Conv2d(kernel_size=7, in_channels=64, out_channels=512, groups=8),\n",
    "                      nn.Conv2d(kernel_size=7, in_channels=64, out_channels=512, groups=16),\n",
    "                      nn.Conv2d(kernel_size=7, in_channels=64, out_channels=512, groups=64),\n",
    "                     ]\n",
    "module_collection_stats = tracker.track_module_collection(module_collection=module_collection, inputs=inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1a360bcd-1c7c-4acc-b631-07da90089d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: shape: torch.Size([1, 64, 224, 224]),loaded on cuda in: 4.15s, memory consumption: 12.85 MB\n",
      " Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1)): run takes 0.81 +- 0.27s, loaded on cuda in 0.6057279706001282s, \n",
      "    module size 0.13 MB, outputs size 92.60 MB\n",
      " Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1)): run takes 2.21 +- 0.74s, loaded on cuda in 0.4540799856185913s, \n",
      "    module size 1.18 MB, outputs size 91.90 MB\n",
      " Conv2d(64, 512, kernel_size=(5, 5), stride=(1, 1)): run takes 5.50 +- 1.83s, loaded on cuda in 0.8712000250816345s, \n",
      "    module size 3.28 MB, outputs size 92.16 MB\n",
      " Conv2d(64, 512, kernel_size=(7, 7), stride=(1, 1)): run takes 10.22 +- 3.41s, loaded on cuda in 1.5380480289459229s, \n",
      "    module size 6.42 MB, outputs size 93.38 MB\n",
      " Conv2d(64, 512, kernel_size=(7, 7), stride=(1, 1), groups=2): run takes 5.30 +- 1.77s, loaded on cuda in 0.8895360231399536s, \n",
      "    module size 3.21 MB, outputs size 90.49 MB\n",
      " Conv2d(64, 512, kernel_size=(7, 7), stride=(1, 1), groups=4): run takes 2.83 +- 0.94s, loaded on cuda in 0.5043839812278748s, \n",
      "    module size 1.61 MB, outputs size 89.04 MB\n",
      " Conv2d(64, 512, kernel_size=(7, 7), stride=(1, 1), groups=8): run takes 1.62 +- 0.54s, loaded on cuda in 0.42604801058769226s, \n",
      "    module size 0.80 MB, outputs size 88.32 MB\n",
      " Conv2d(64, 512, kernel_size=(7, 7), stride=(1, 1), groups=16): run takes 1.11 +- 0.37s, loaded on cuda in 0.3256320059299469s, \n",
      "    module size 0.40 MB, outputs size 87.96 MB\n",
      " Conv2d(64, 512, kernel_size=(7, 7), stride=(1, 1), groups=64): run takes 1.96 +- 0.65s, loaded on cuda in 0.4449920058250427s, \n",
      "    module size 0.10 MB, outputs size 87.69 MB\n",
      "\n",
      "fastest module is Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1)) with 0.81s\n",
      "slowest module is Conv2d(64, 512, kernel_size=(7, 7), stride=(1, 1)) with 10.22s\n",
      "\n",
      "tiniest module is Conv2d(64, 512, kernel_size=(7, 7), stride=(1, 1), groups=64) with 87.69MB\n",
      "biggest module is Conv2d(64, 512, kernel_size=(7, 7), stride=(1, 1)) with 93.38MB\n"
     ]
    }
   ],
   "source": [
    "warmup_tracker = Tracker(device, warmup=10)\n",
    "inputs = torch.randn((1, 64, 224, 224))\n",
    "\n",
    "module_collection = [nn.Conv2d(kernel_size=1, in_channels=64, out_channels=512), \n",
    "                      nn.Conv2d(kernel_size=3, in_channels=64, out_channels=512), \n",
    "                      nn.Conv2d(kernel_size=5, in_channels=64, out_channels=512),\n",
    "                      nn.Conv2d(kernel_size=7, in_channels=64, out_channels=512),\n",
    "                      nn.Conv2d(kernel_size=7, in_channels=64, out_channels=512, groups=2),\n",
    "                      nn.Conv2d(kernel_size=7, in_channels=64, out_channels=512, groups=4),\n",
    "                      nn.Conv2d(kernel_size=7, in_channels=64, out_channels=512, groups=8),\n",
    "                      nn.Conv2d(kernel_size=7, in_channels=64, out_channels=512, groups=16),\n",
    "                      nn.Conv2d(kernel_size=7, in_channels=64, out_channels=512, groups=64),\n",
    "                     ]\n",
    "warmup_module_collection_stats = warmup_tracker.track_module_collection(module_collection=module_collection, inputs=inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eabbee-e5a1-44d1-994c-1304d5b661b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
